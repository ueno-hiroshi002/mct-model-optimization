{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9ca09f9",
   "metadata": {},
   "source": [
    "# Model Compression Toolkit (MCT) Wrapper API (Keras)\n",
    "\n",
    "[Run this tutorial in Google Colab](https://colab.research.google.com/github/SonySemiconductorSolutions/mct-model-optimization/blob/main/tutorials/notebooks/mct_features_notebooks/keras/example_keras_mct_wrapper.ipynb)\n",
    "\n",
    "### Attention\n",
    "\n",
    "The MCT (Model Compression Toolkit) used in this tutorial requires TensorFlow 2.15 or earlier, which are not compatible with the default Google Colab environment (Python 3.12 or later).\n",
    "\n",
    "**If you are running this tutorial on Google Colab, you must change the runtime type to use Python 3.11 before proceeding.**  \n",
    "For detailed instructions, please refer to the [README.md](../../../README.md).\n",
    "\n",
    "## Overview \n",
    "In this notebook, we provide a detailed explanation of the MCTWrapper class from the Model Compression Toolkit (MCT).\n",
    "Using this class enables a consistent implementation, making it easy to compare various quantization methods.\n",
    "In this tutorial, we take MobileNetV2 as an example and use MCTWrapper to apply the following quantization techniques:\n",
    "PTQ (Post-Training Quantization), PTQ with Mixed Precision, GPTQ (Gradient-based PTQ), GPTQ with Mixed Precision.\n",
    "By working through these methods, you will experience the convenience and flexibility of MCTWrapper, \n",
    "helping you to select the optimal quantization approach for your application.\n",
    "\n",
    "## Summary\n",
    "- **Setup**: Import required libraries and configure MCT with MobileNetV2 model\n",
    "- **Dataset Preparation**: Load and prepare ImageNet validation dataset with representative data generation\n",
    "- **Model Quantization using MCTWrapper**: Quantize the float model using MCTWrapper with four methods\n",
    "  - **PTQ**: Perform PTQ\n",
    "  - **PTQ + Mixed Precision**: Assign optimal quantization bit-width to each layer based on PTQ\n",
    "  - **GPTQ**: Perform GPTQ\n",
    "  - **GPTQ + Mixed Precision**: Assign optimal quantization bit-width to each layer based on GPTQ\n",
    "- **Evaluation**: Evaluate accuracy of all quantization methods\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e667e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_VER = '2.15.0'\n",
    "!pip install -q tensorflow~={TF_VER}\n",
    "!pip install -q scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e138ad45-68d2-4c34-95ac-1a327ce54406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "if not importlib.util.find_spec('model_compression_toolkit'):\n",
    "    !pip install model_compression_toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0ece2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "from typing import Tuple, Generator, List, Any\n",
    "import model_compression_toolkit as mct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60853205",
   "metadata": {},
   "source": [
    "Load a pre-trained MobileNetV2 model from Keras, in 32-bits floating-point precision format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e743078d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "\n",
    "float_model = MobileNetV2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dce48a1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Dataset Preparation\n",
    "### Download ImageNet validation set\n",
    "Download ImageNet dataset (validation split only).\n",
    "\n",
    "This step may take several minutes...\n",
    "\n",
    "**Note:** For demonstration purposes, we use the validation set for the model quantization routines. Usually, a subset of the training dataset is used, but loading it is a heavy procedure that is unnecessary for the sake of this demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f14d92-5116-40b7-9090-f378bdf3cc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    " \n",
    "if not os.path.isdir('imagenet'):\n",
    "    !mkdir imagenet\n",
    "    !wget -P imagenet https://image-net.org/data/ILSVRC/2012/ILSVRC2012_devkit_t12.tar.gz\n",
    "    !wget -P imagenet https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_val.tar\n",
    "    \n",
    "    !cd imagenet && tar -xzf ILSVRC2012_devkit_t12.tar.gz && \\\n",
    "     mkdir ILSVRC2012_img_val && tar -xf ILSVRC2012_img_val.tar -C ILSVRC2012_img_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41859aab",
   "metadata": {},
   "source": [
    "The following code organizes the extracted data into separate folders for each label, making it compatible with Keras dataset loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4bd4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "root = Path('./imagenet')\n",
    "imgs_dir = root / 'ILSVRC2012_img_val'\n",
    "target_dir = root /'val'\n",
    "\n",
    "def extract_labels():\n",
    "    mat = scipy.io.loadmat(root / 'ILSVRC2012_devkit_t12/data/meta.mat', squeeze_me=True)\n",
    "    cls_to_nid = {s[0]: s[1] for i, s in enumerate(mat['synsets']) if s[4] == 0} \n",
    "    with open(root / 'ILSVRC2012_devkit_t12/data/ILSVRC2012_validation_ground_truth.txt', 'r') as f:\n",
    "        return [cls_to_nid[int(cls)] for cls in f.readlines()]\n",
    "\n",
    "if not target_dir.exists():\n",
    "    labels = extract_labels()\n",
    "    for lbl in set(labels):\n",
    "        os.makedirs(target_dir / lbl)\n",
    "    \n",
    "    for img_file, lbl in zip(sorted(os.listdir(imgs_dir)), labels):\n",
    "        shutil.move(imgs_dir / img_file, target_dir / lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8dd14b",
   "metadata": {},
   "source": [
    "These functions generate a `tf.data.Dataset` from image files in a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5212d5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imagenet_preprocess_input(images: tf.Tensor, labels: tf.Tensor):\n",
    "    return tf.keras.applications.mobilenet_v2.preprocess_input(images), labels\n",
    "\n",
    "def get_dataset(batch_size: int, shuffle: bool):\n",
    "    dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "        directory='./imagenet/val',\n",
    "        batch_size=batch_size,\n",
    "        image_size=[224, 224],\n",
    "        shuffle=shuffle,\n",
    "        crop_to_aspect_ratio=True,\n",
    "        interpolation='bilinear')\n",
    "    dataset = dataset.map(lambda x, y: (imagenet_preprocess_input(x, y)), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c490a2e",
   "metadata": {},
   "source": [
    "## Representative Dataset\n",
    "For quantization with MCT, we need to define a representative dataset. This dataset is a generator that returns a list of images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f60a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "n_iter = 10\n",
    "\n",
    "dataset = get_dataset(batch_size, shuffle=True)\n",
    "\n",
    "def representative_dataset_gen():\n",
    "    for _ in range(n_iter):\n",
    "        yield [dataset.take(1).get_single_element()[0].numpy()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa8e319",
   "metadata": {},
   "source": [
    "## Model Quantization using MCTWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8968510f",
   "metadata": {},
   "source": [
    "We implement quantizing example using MCTWrapper with four methods.\n",
    "\n",
    "By specifying the SDSP converter version, you can select the optimal quantization settings for IMX500.\n",
    "Here, we use the settings for SDSP Converter 3.14. For other settings, please see [here](https://github.com/SonySemiconductorSolutions/mct-model-optimization/tree/main/model_compression_toolkit/target_platform_capabilities).\n",
    "\n",
    "**Note:** This tutorial sets the minimum parameters required to run MCTWrapper. For details on omitted parameters, refer to [MCT Documentation](https://sonysemiconductorsolutions.github.io/mct-model-optimization/api/api_docs/classes/Wrapper.html#ug-wrapper).\n",
    "\n",
    "**Note:** This tutorial uses parameters focused on shorter run time for demonstration, resulting in lower accuracy. For improve accuracy, refer to other tutorials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf35f64",
   "metadata": {
    "cell_marker": "#########################################################################",
    "lines_to_next_cell": 0
   },
   "source": [
    "Run PTQ with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e151ddca",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def PTQ_Keras(float_model: keras.Model) -> Tuple[bool, keras.Model]:\n",
    "    \"\"\"\n",
    "    Perform PTQ on Keras model.\n",
    "    \n",
    "    Args:\n",
    "        float_model: Original floating-point Keras model\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (success_flag, quantized_model)\n",
    "    \"\"\"\n",
    "    # Configuration\n",
    "    framework = 'tensorflow'          # Target framework (Keras/TensorFlow)\n",
    "    method = 'PTQ'                    # Quantization method\n",
    "    use_mixed_precision = False       # Disable mixed-precision quantization\n",
    "\n",
    "    # Parameter configuration for PTQ\n",
    "    param_items = [\n",
    "        ['sdsp_version', '3.14'],                          # Version of the SDSP converter\n",
    "        ['save_model_path', './qmodel_PTQ_Keras.keras']    # Path to save quantized model as Keras format\n",
    "    ]\n",
    "\n",
    "    # Execute quantization using MCTWrapper\n",
    "    wrapper = mct.wrapper.mct_wrapper.MCTWrapper()\n",
    "    flag, quantized_model = wrapper.quantize_and_export(\n",
    "        float_model=float_model, \n",
    "        representative_dataset=representative_dataset_gen,\n",
    "        framework=framework, \n",
    "        method=method, \n",
    "        use_mixed_precision=use_mixed_precision, \n",
    "        param_items=param_items)\n",
    "    return flag, quantized_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7f6eeb",
   "metadata": {
    "cell_marker": "#########################################################################",
    "lines_to_next_cell": 0
   },
   "source": [
    "Run PTQ + Mixed Precision with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c082471a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def PTQ_Keras_mixed_precision(float_model: keras.Model) -> Tuple[bool, keras.Model]:\n",
    "    \"\"\"\n",
    "    Perform PTQ with Mixed Precision on Keras model.\n",
    "    \n",
    "    Args:\n",
    "        float_model: Original floating-point Keras model\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (success_flag, quantized_model)\n",
    "    \"\"\"\n",
    "    # Configuration\n",
    "    framework = 'tensorflow'          # Target framework (Keras/TensorFlow)\n",
    "    method = 'PTQ'                    # Quantization method\n",
    "    use_mixed_precision = True        # Enable mixed-precision quantization\n",
    "\n",
    "    # Parameter configuration\n",
    "    param_items = [\n",
    "        ['sdsp_version', '3.14'],                                         # Version of the SDSP converter\n",
    "        ['num_of_images', 5],                                             # Number of images for Mixed-Precision calibration\n",
    "        ['weights_compression_ratio', 0.5],                               # Compression ratio of weights for Mixed-Precision\n",
    "        ['save_model_path', './qmodel_PTQ_Keras_mixed_precision.keras']   # Path to save quantized model as Keras format\n",
    "    ]\n",
    "\n",
    "    # Execute quantization using MCTWrapper\n",
    "    wrapper = mct.wrapper.mct_wrapper.MCTWrapper()\n",
    "    flag, quantized_model = wrapper.quantize_and_export(\n",
    "        float_model=float_model, \n",
    "        representative_dataset=representative_dataset_gen,\n",
    "        framework=framework, \n",
    "        method=method, \n",
    "        use_mixed_precision=use_mixed_precision, \n",
    "        param_items=param_items)\n",
    "    return flag, quantized_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269f2cba",
   "metadata": {
    "cell_marker": "#########################################################################",
    "lines_to_next_cell": 0
   },
   "source": [
    "Run GPTQ (Gradient-based PTQ) with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82c0070",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def GPTQ_Keras(float_model: keras.Model) -> Tuple[bool, keras.Model]:\n",
    "    \"\"\"\n",
    "    Perform GPTQ on Keras model.\n",
    "    \n",
    "    Args:\n",
    "        float_model: Original floating-point Keras model\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (success_flag, quantized_model)\n",
    "    \"\"\"\n",
    "    # Configuration\n",
    "    framework = 'tensorflow'          # Target framework (Keras/TensorFlow)\n",
    "    method = 'GPTQ'                   # Quantization method\n",
    "    use_mixed_precision = False       # Disable mixed-precision quantization\n",
    "\n",
    "    # Parameter configuration\n",
    "    param_items = [\n",
    "        ['sdsp_version', '3.14'],                          # Version of the SDSP converter\n",
    "        ['n_epochs', 5],                                   # Number of epochs for GPTQ optimization\n",
    "        ['save_model_path', './qmodel_GPTQ_Keras.keras']   # Path to save quantized model as Keras format\n",
    "    ]\n",
    "\n",
    "    # Execute quantization using MCTWrapper\n",
    "    wrapper = mct.wrapper.mct_wrapper.MCTWrapper()\n",
    "    flag, quantized_model = wrapper.quantize_and_export(\n",
    "        float_model=float_model, \n",
    "        representative_dataset=representative_dataset_gen,\n",
    "        framework=framework, \n",
    "        method=method, \n",
    "        use_mixed_precision=use_mixed_precision, \n",
    "        param_items=param_items)\n",
    "    return flag, quantized_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9d77b5",
   "metadata": {
    "cell_marker": "#########################################################################",
    "lines_to_next_cell": 0
   },
   "source": [
    "Run GPTQ + Mixed Precision with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e06b4e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def GPTQ_Keras_mixed_precision(float_model: keras.Model) -> Tuple[bool, keras.Model]:\n",
    "    \"\"\"\n",
    "    Perform GPTQ with Mixed Precision on Keras model.\n",
    "    \n",
    "    Args:\n",
    "        float_model: Original floating-point Keras model\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (success_flag, quantized_model)\n",
    "    \"\"\"\n",
    "    # Configuration\n",
    "    framework = 'tensorflow'          # Target framework (Keras/TensorFlow)\n",
    "    method = 'GPTQ'                   # Quantization method\n",
    "    use_mixed_precision = True        # Enable mixed-precision quantization\n",
    "\n",
    "    # Parameter configuration\n",
    "    param_items = [\n",
    "        ['sdsp_version', '3.14'],                                          # Version of the SDSP converter\n",
    "        ['n_epochs', 5],                                                   # Number of epochs for GPTQ optimization\n",
    "        ['num_of_images', 5],                                              # Number of images for Mixed-Precision calibration\n",
    "        ['weights_compression_ratio', 0.5],                                # Compression ratio of weights for Mixed-Precision\n",
    "        ['save_model_path', './qmodel_GPTQ_Keras_mixed_precision.keras']   # Path to save quantized model as Keras format\n",
    "    ]\n",
    "\n",
    "    # Execute quantization using MCTWrapper\n",
    "    wrapper = mct.wrapper.mct_wrapper.MCTWrapper()\n",
    "    flag, quantized_model = wrapper.quantize_and_export(\n",
    "        float_model=float_model, \n",
    "        representative_dataset=representative_dataset_gen,\n",
    "        framework=framework, \n",
    "        method=method, \n",
    "        use_mixed_precision=use_mixed_precision, \n",
    "        param_items=param_items)\n",
    "    return flag, quantized_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314fc4ce",
   "metadata": {},
   "source": [
    "### Run Quantization\n",
    "Lastly, we quantize our model using MCTWrapper API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce5ebd0-aa83-4bb7-9e23-5ae3b95858dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Basic PTQ\n",
    "flag, quantized_model_ptq = PTQ_Keras(float_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9990c4d4-0ffe-4069-ba9b-6d14e9722edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PTQ with Mixed Precision\n",
    "flag, quantized_model_ptq_mixed_precision = PTQ_Keras_mixed_precision(float_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b952197-11c2-4373-842e-ce3b264ca5b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GPTQ\n",
    "flag, quantized_model_gptq = GPTQ_Keras(float_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075a2012-9423-4eaa-84c7-365a5daafa6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GPTQ with Mixed Precision\n",
    "flag, quantized_model_gptq_mixed_precision = GPTQ_Keras_mixed_precision(float_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b34232",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Create dataset loader for evaluation with larger batch size for efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce90826-e5c5-4be0-8b54-96795eab47eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = get_dataset(batch_size=50, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7187f120",
   "metadata": {},
   "source": [
    "Finally, let's evaluate each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e01931d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original floating-point Keras model\n",
    "float_model.compile(loss=keras.losses.SparseCategoricalCrossentropy(), metrics=\"accuracy\")\n",
    "float_accuracy = float_model.evaluate(val_dataset)\n",
    "print(f\"Float model Accuracy: {(float_accuracy[1] * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cabfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PTQ model\n",
    "quantized_model_ptq.compile(loss=keras.losses.SparseCategoricalCrossentropy(), metrics=\"accuracy\")\n",
    "ptq_quantized_accuracy = quantized_model_ptq.evaluate(val_dataset)\n",
    "print(f\"PTQ_Keras Accuracy: {(ptq_quantized_accuracy[1] * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a42b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PTQ + Mixed Precision model\n",
    "quantized_model_ptq_mixed_precision.compile(loss=keras.losses.SparseCategoricalCrossentropy(), metrics=\"accuracy\")\n",
    "ptq_mixed_precision_quantized_accuracy = quantized_model_ptq_mixed_precision.evaluate(val_dataset)\n",
    "print(f\"PTQ_Keras_mixed_precision Accuracy: {(ptq_mixed_precision_quantized_accuracy[1] * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad8438d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPTQ model\n",
    "quantized_model_gptq.compile(loss=keras.losses.SparseCategoricalCrossentropy(), metrics=\"accuracy\")\n",
    "gptq_quantized_accuracy = quantized_model_gptq.evaluate(val_dataset)\n",
    "print(f\"GPTQ_Keras Accuracy: {(gptq_quantized_accuracy[1] * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46335127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPTQ + Mixed Precision model\n",
    "quantized_model_gptq_mixed_precision.compile(loss=keras.losses.SparseCategoricalCrossentropy(), metrics=\"accuracy\")\n",
    "gptq_mixed_precision_quantized_accuracy = quantized_model_gptq_mixed_precision.evaluate(val_dataset)\n",
    "print(f\"GPTQ_Keras_mixed_precision Accuracy: {(gptq_mixed_precision_quantized_accuracy[1] * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e71f63d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, we demonstrated how to quantize a pre-trained model using MCTWrapper with a few lines of code.\n",
    "\n",
    "## Copyrights\n",
    "\n",
    "Copyright 2025 Sony Semiconductor Solutions, Inc. All rights reserved.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "keras5 (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
